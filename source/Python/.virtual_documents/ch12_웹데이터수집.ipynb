





import requests
from requests_file import FileAdapter


s = requests.Session()
s.mount("file://", FileAdapter())
response = s.get('file:///C:/IVS/C_Python/source/Python/ch12_sample.html')
#C:\IVS\C_Python\source\Pythonch12_sample.html
response  #200뜨면 정상, 404뜨면 오류


if response.status_code == 200:
    print('success!')
if response.status_code == 404:
    print('Not found')


response.content.decode('utf-8')


# html 파싱
from bs4 import BeautifulSoup # 클래스 이름
soup=BeautifulSoup(response.content,"html.parser") #xml은?
soup


el = soup.select_one('h1') #처음 하나만 가져옴
print(el)
print('el.text :', el.text) #모든 태그를 뺀 텍스트만
print('el의 속성들 :', el.attrs)
print('el의 class속성 :', el.attrs['class'])
print('el의 name :', el.name) #태그이름


# h1태그들 다 : 없는 태그는 빈스트링. 한 엘리먼트만 있어도 리스트로 반환
el = soup.select("h1")
print('el : ', el)
print('el의 text들 :', [e.text for e in el])
print('el의 string :', [e.string for e in el])
print('el의 속성들 :', [e.attrs for e in el])
print('el의 class속성들 :', [e.attrs['class'] for e in el])


# h1태그들 다 : 없는 태그는 빈스트링. 한 엘리먼트만 있어도 리스트로 반환
el = soup.select('div.contents')
print('el : ', el)
print('el의 text들 :', [e.text for e in el])
print('el의 string :', [e.string for e in el])
print('el의 속성들 :', [e.attrs for e in el])
print('el의 class속성들 :', [e.attrs['class'] for e in el])


el = soup.select('div.contents')
el = soup.select_one('div.contents')
print(el.text)





import requests
from bs4 import BeautifulSoup
from numpy import round
url = "https://finance.naver.com/marketindex"
marketindex = requests.get(url)
soup = BeautifulSoup(marketindex.content, "html.parser")
price = soup.select("div.head_info > span.value")
for idx in range(len(price)):
    print(price[idx].text)


marketindex.content  # html 파일


title = soup.select('h3.h_lst > span.blind')
for idx in range(len(title)):
    print(title[idx].text)


unit = soup.select('div.head_info > span > span.blind')
unit = [u.text for u in unit]
unit.insert(7,'')
unit


status = soup.select('div.head_info > span.blind')
for idx in range(len(status)):
    print(status[idx].text, end=', ')


len(title), len(price), len(unit), len(status)


for idx in range(len(title)):
    print("{} : {}{} - {}".format(title[idx].text, price[idx].text, 
                                 unit[idx], status[idx].text))





import requests
from urllib.request import urlopen
from bs4 import BeautifulSoup
url = "http://www.yes24.com/24/category/bestseller"
# bestseller = requests.get(url)
# soup = BeautifulSoup(bestseller.content, "html.parser")
bestseller = urlopen(url)
soup = BeautifulSoup(bestseller, "html.parser")
authors_ = soup.select("div.info_row > span.info_auth.authPub")
for idx in range(len(el)):
    print(el[idx].select_one('a').text, end="\n\n")


import requests
from urllib.request import urlopen
from bs4 import BeautifulSoup
url = "http://www.yes24.com/24/category/bestseller"
# bestseller = requests.get(url)
# soup = BeautifulSoup(bestseller.content, "html.parser")
bestseller = urlopen(url)
soup = BeautifulSoup(bestseller, "html.parser")
titles=soup.select("div.item_info > div.info_row > a.gd_name")
# authors = soup.select("div.info_row > span.info_auth.authPub > a")
authors_wrap = soup.select("div.info_row > span.info_auth.authPub")
prices = soup.select("div.info_row > strong.txt_num > em.yes_b")
# 화면출력
print("순위,책이름,저자및출판사,가격")
title = []
author = []
price = []
for idx in range(len(titles)):
    authors = authors_wrap[idx].select_one('a')
    print("{},{},{},{}".format(idx+1, titles[idx].text, authors.text,  prices[idx].text))
    # print("{},{},{},{}".format(idx+1, titles[idx].text, authors[idx].text,  prices[idx].text))
    title.append(titles[idx].text)
    author.append(authors.text)
    price.append(prices[idx].text)


import pandas as pd
df = pd.DataFrame({'순위':range(1,25),
                   '책이름':title,
                   '저자및출판사':author,
                   '가격':price})
df


df.to_csv('data/yes24.csv', encoding='utf-8', index=False)



